{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is an example for the use of sklearn pipeline and it's addons we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import dill\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from main_pipeline import ObjectsColumnaAsType, PandasImputer, PandasStandardScaler,TypeSelector\n",
    "from pandas_feature_union import PandasFeatureUnion\n",
    "from pandas_OneHotEncoder import OneHotEncoder\n",
    "# from data_inspection import *\n",
    "from preprocessing_pipeline import *\n",
    "from classification_metrics import *\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('data/users_dataset_for_models.csv', index_col= '_id')\n",
    "# Train Test split\n",
    "X, y = input_data.drop(columns = ['label']), input_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing pipeline\n",
    "Each column in the input data is is going into column selector and the to another class which does the preproccess on the vector\n",
    "Columns that do not need preprocess go to the `other_cols` varaibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_data.copy()\n",
    "def apply_log(x,log = np.log):\n",
    "    return log(1+x)\n",
    "\n",
    "gender = make_pipeline(ColumnSelector('gender'),GenderColumnInOptions())\n",
    "name_language = make_pipeline(ColumnSelector('name_language'),NameLanguageColumnInOptions())\n",
    "# example for flexibility\n",
    "hometown_region = make_pipeline(ColumnSelector('hometown_region'),ColumnInOptions(['Central District', 'Tel Aviv', 'Southern District', 'Heifa', 'Jerusalem']))\n",
    "phone_exists = make_pipeline(ColumnSelector('phone'),ColumnExist())\n",
    "# example for flexibility\n",
    "log_likes = make_pipeline(ColumnSelector('likes_count'),ColumnApplyFunc(apply_log))\n",
    "log_friends = make_pipeline(ColumnSelector('friends_count'),ColumnApplyFunc(apply_log))\n",
    "other_cols = ['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grouping the previews pipelines to one pipeline - pre procees pipeline\n",
    "PandasFeatureUnion unites the different vectors to a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = make_pipeline(\n",
    "    PandasFeatureUnion(transformer_list=[\n",
    "    (\"gender\",gender),\n",
    "    (\"name_language\",name_language),\n",
    "    (\"hometown_region\",hometown_region),\n",
    "    (\"phone_exists\",phone_exists),\n",
    "    (\"log_likes\",log_likes),\n",
    "    (\"log_friends\",log_friends),   \n",
    "     (\"other_columns\",ColumnSelector(columns= other_cols))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizers\n",
    "After the preprocess pipeline each type of variable {numeric,boolean, categorial}\n",
    "is going to:\n",
    "    \n",
    "    imputer - fill missing values\n",
    "    normalizer - numeric vectors are scaled to standard normal distribution,\n",
    "        castegorial varaibles are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = make_pipeline(\n",
    "    pre_process,\n",
    "    ObjectsColumnaAsType(),\n",
    "    PandasFeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            TypeSelector(np.number),\n",
    "            PandasImputer(strategy=\"mean\"),\n",
    "            PandasStandardScaler()\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            TypeSelector(\"category\"),\n",
    "            PandasImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder()\n",
    "        )),\n",
    "        (\"boolean_features\", make_pipeline(\n",
    "            TypeSelector(\"bool\"),\n",
    "        ))\n",
    "]))\n",
    "\n",
    "preprocess_pipeline.fit(X_train)\n",
    "X_train = preprocess_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnig a wrapper of sklearn frid search - search for the best hyper parameters.\n",
    "the code was taken from -\n",
    "\n",
    "http://www.davidsbatista.net/blog/2018/02/23/model_optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for lr.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.873447</td>\n",
       "      <td>0.875477</td>\n",
       "      <td>0.877322</td>\n",
       "      <td>0.0015759</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.873447</td>\n",
       "      <td>0.875477</td>\n",
       "      <td>0.877322</td>\n",
       "      <td>0.00157585</td>\n",
       "      <td>2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.873448</td>\n",
       "      <td>0.875477</td>\n",
       "      <td>0.877322</td>\n",
       "      <td>0.00157489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.873449</td>\n",
       "      <td>0.875476</td>\n",
       "      <td>0.877319</td>\n",
       "      <td>0.00157317</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimator min_score mean_score max_score   std_score    C solver\n",
       "3        lr  0.873447   0.875477  0.877322   0.0015759    1  lbfgs\n",
       "0        lr  0.873447   0.875477  0.877322  0.00157585    2  lbfgs\n",
       "2        lr  0.873448   0.875477  0.877322  0.00157489  0.2  lbfgs\n",
       "1        lr  0.873449   0.875476  0.877319  0.00157317  0.1  lbfgs"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grid_search_helper import *\n",
    "\n",
    "models = {\n",
    "    'lr': LogisticRegression(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'lr': [{'solver': ['lbfgs'],'C': [2]},\n",
    "           {'solver': ['lbfgs'],'C': [0.1,0.2,1]} \n",
    "    ]}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "best_model = helper.fit(X_train, y_train, scoring='roc_auc', n_jobs=8, cv =5)\n",
    "helper.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the final pipeline - adding the best model to the preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline = make_pipeline(preprocess_pipeline , best_model)\n",
    "# now we have a prediction machine that takes raw data and provides a label/probability\n",
    "final_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is possible to access internal data from the pipeline - quite complex - need trial and error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Central District', 'Tel Aviv', 'Southern District', 'Heifa', 'Jerusalem']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excessing objects\n",
    "preprocess_pipeline.named_steps['pandasfeatureunion'].get_params()['numeric_features__pandasstandardscaler'].transformer.mean_\n",
    "hometown_region.named_steps['columninoptions'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(final_pipeline, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for using the model we created on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
